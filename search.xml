<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Windows + Flask + Apache + wsgi部署word转pdf服务]]></title>
    <url>%2Fposts%2F2020%2F05%2F16%2FWindows%20%2B%20Flask%20%2B%20Apache%20%2B%20wsgi%E9%83%A8%E7%BD%B2word%E8%BD%ACpdf%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[一、安装Apache服务下载最新的Apache：下载地址：https://httpd.apache.org 选择版本的时候需要选择与Python的版本一致的Apache，Apache,mod_wsgi和Python都必须用相同版本的C/C++编译器生成，要么都是32位的，要么都是64位的，不能混用。这边选则x64,vc15的版本。 下载完成后解压到安装目录，修改conf/httpd.conf配置文件 1Define SRVROOT &quot;D:/Apache24&quot; #修改为对应的安装目录 可能用到的配置123456789101112LoadModule access_compat_module modules/mod_access_compat.so #基于主机的组授权（名称或IP地址） httpd 2.x兼容的模块，LoadModule proxy_module modules/mod_proxy.so #apache的代理模块LoadModule proxy_http_module modules/mod_proxy_http.so #代理http和https请求LoadModule vhost_alias_module modules/mod_vhost_alias.so #虚拟主机动态配置LoadModule authz_host_module modules/mod_authz_host.so #基于主机的组授权Include conf/extra/httpd-vhosts.conf#启用虚拟主机配置 命令行启动httpd.exe，并验证是否启动成功，正常显示Apache测试页面就没有问题 创建Windows 服务1httpd.exe -k install -n "apache2.4" #apache2.4是所创建服务的名称，可更改。 安装服务后就可以使用ApacheMonitor来管理服务的启停了 二、安装Apache mod_wsgi模块下载对应版本的mod_wsgi并安装：下载地址：https://www.lfd.uci.edu/~gohlke/pythonlibs/找到对应版本的whl文件下载 Apache和mod_wsgi 必须选择相同位数相同VC编译版本（比如：都是x64 VC14编译）这边选择Apache24版本vc15编译Python3.7 64位版 下载完成后就可以直接通过pip工具来进行安装 1pip3 install "mod_wsgi‑4.7.1+ap24vc15‑cp37‑cp37m‑win_amd64.whl" 安装后运行 1mod_wsgi-express module-config 获取配置信息 123LoadFile "c:/users/lin/appdata/local/programs/python/python37/python37.dll"LoadModule wsgi_module "c:/users/lin/appdata/local/programs/python/python37/lib/site-packages/mod_wsgi/server/mod_wsgi.cp37-win_amd64.pyd"WSGIPythonHome "c:/users/lin/appdata/local/programs/python/python37" 配置信息需要存下来，后续配置需要用到 配置mod_wsgi模块：再次打开httpd.conf文件，再最末尾添加如下代码，具体解释看注释，实际情况根据自己的项目位置更改。1234567891011121314# 1.安装wsgi模块后，出来的三行字符，直接复制过来LoadFile &quot;c:/users/lin/appdata/local/programs/python/python37/python37.dll&quot;LoadModule wsgi_module &quot;c:/users/lin/appdata/local/programs/python/python37/lib/site-packages/mod_wsgi/server/mod_wsgi.cp37-win_amd64.pyd&quot;WSGIPythonHome &quot;c:/users/lin/appdata/local/programs/python/python37&quot;# 2.设置工程中的wsgi路径WSGIScriptAlias / c:/home/web/word2pdf.wsgi# 3.设置工程路径WSGIPythonPath c:/home/web# 4.设置wsgi路径&lt;Directory c:/home/web&gt; &lt;Files word2pdf.wsgi&gt; Require all granted &lt;/Files&gt;&lt;/Directory&gt; word2pdf.wsgi内容1234567import syssys.path.insert(0, "C:/home/web")from word2pdf import appapplication = app 本例word2pdf.py 与 wsgi文件在同一层级 三、Windows 服务下启动Apache无法调用Word软件问题解决方案系统部署后发现，当使用命令行启动Apache的时候，可以正常调起Word程序进行转换，但当Apache改成服务方式启动，程序就会报错。经调查后发现是由于Windows Vista/2008起Windows改变了COM对象默认的交互方式为“非交互”型的。命令行启动本身支持应用交互，但service模式下就不行了。所以需要修改Word DCOM默认的标识，改为“交互式用户”模式，即可正常调用了。 在”开始”-&gt;”运行”中输入dcomcnfg.exe启动”组件服务” 依次双击”组件服务”-&gt;”计算机”-&gt;”我的电脑”-&gt;”DCOM配置” 在”DCOM配置”中找到”Microsoft Word 97 - 2003 Document”，击右键,然后点击”属性”，选标识，将启动用户改成交互式用户 在安全选项卡中启动与激活权限改成自定义，点编辑，看看当前登录用户时候有在列表中，如果没在列表中点击添加，对象名称中输入用户名确认返回。 权限中勾选本地启动和本地激活两项。 同样的方法设置“访问权限”中勾选本地访问权限。 [1] Windows + Flask + Apache + wsgi踏坑总结[2] Windows下部Django（Apache+mod_wsgi）[3] 如何解决Windows Server 2008 服务启动不能调用Office Word的问题[4] window2008 64位系统无法调用Microsoft.Office.Interop组件进行文件另存的解决办法]]></content>
      <categories>
        <category>Python</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>wsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS环境下共存python3部署scrapyd笔记]]></title>
    <url>%2Fposts%2F2019%2F05%2F15%2FCentOS%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%85%B1%E5%AD%98python3%E9%83%A8%E7%BD%B2scrapyd%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[为了使爬虫支持javascript，爬虫的使用了selenium，所以本文也会宝行seleniun与phantomjs的安装配置。 可能需要的依赖有： 1[root@localhost ~]# yum -y install openssl-devel libffi-devel tk-devel bzip2 openssl-devel：缺少该依赖scrapyd虽然可以安装成功，但是运行会报错 libffi-devel tk-devel：将报错ModuleNotFoundError: No module named ‘_ctypes’ bzip2：用于源码解压 一、Python3共存安装1.下载Python最新源码官网：https://www.python.org/downloads/source/ 下载最新稳定版代码并解压 2. 开启_ssl模块scrapyd运行需要python3开启_ssl相关代码，否则报缺失ssl模块错误。开启方法： 首先进入Python-3.7.3/Modules目录下，编辑Setup.dist与Setup文件（大概在50%的位置），将红线处注释去掉 1234567891011121314#SSL=/usr/local/ssl#_ssl _ssl.c \# -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \# -L$(SSL)/lib -lssl -lcrypto# Socket module helper for socket(2)_socket socketmodule.c# Socket module helper for SSL support; you must comment out the other# socket line above, and possibly edit the SSL variable:SSL=/usr/local/ssl_ssl _ssl.c \ -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \ -L$(SSL)/lib -lssl -lcrypto 3. 安装sqlite3编译python3 之前需要先加入sqlite3，缺少该模块scrapyd运行报错： builtins.ModuleNotFoundError: No module named ‘_sqlite3’ 尝试过直接使用yum直接安装，但是scrapyd依旧无法调用相应的库。解决方法如下： 12345[root@localhost ~]# wget https://www.sqlite.org/2017/sqlite-autoconf-3170000.tar.gz --no-check-certificate[root@localhost ~]# tar xf sqlite-autoconf-3170000.tar.gz[root@localhost ~]# cd sqlite-autoconf-3170000/[root@localhost ~]# ./configure --prefix=/usr/local/sqlite3 --disable-static --enable-fts5 --enable-json1 CFLAGS="-g -O2 -DSQLITE_ENABLE_FTS3=1 -DSQLITE_ENABLE_FTS4=1 -DSQLITE_ENABLE_RTREE=1"[root@localhost ~]# make &amp;&amp; make install 编译Python3.7 123[root@localhost ~]# LD_RUN_PATH=/usr/local/sqlite3/lib ./configure LDFLAGS="-L/usr/local/sqlite3/lib" CPPFLAGS="-I /usr/local/sqlite3/include"[root@localhost ~]# LD_RUN_PATH=/usr/local/sqlite3/lib make[root@localhost ~]# LD_RUN_PATH=/usr/local/sqlite3/lib sudo make install 运行python3 -V查看是否安装成功 若无法找到python3命令，则建立软链接到/usr/bin 12[root@localhost ~]# ln -s /usr/local/bin/python3 /usr/bin/python3[root@localhost ~]# ln -s /usr/local/bin/pip3 /usr/bin/pip3 运行python3进入python交互界面输入：import sqlite3没报错说明sqlite3安装成功。 Python3共存安装到此完成，运行python用的是系统自带的额python2，运行python3则调用新安装的Python3。 二、安装Scrapy与Selenium新装的Python最好升级一下pip运行 1[root@localhost ~]# pip3 install --upgrade pip 1.安装Twisted依赖下载Twisted 18.9（不要使用最新版的19.0 ，否则后续查看jobs的页面的时候会报错：builtins.AttributeError: ‘int’ object has no attribute ‘splitlines’） 1234[root@localhost ~]# wget https://twistedmatrix.com/Releases/Twisted/18.9/Twisted-18.9.0.tar.bz2[root@localhost ~]# tar -jxvf Twisted-18.9.0.tar.bz2[root@localhost ~]# cd Twisted-18.9.0[root@localhost ~]# python3 setup.py install 2.安装Scrapy与Selenium直接使用pip安装 12[root@localhost ~]# pip3 install Scrapy[root@localhost ~]# scrapy version 能看到Scrapy的版本，安装成功 提示找不到命令则简历软链接 1[root@localhost ~]# ln -s /usr/local/bin/scrapy /usr/bin/scrapy selenium的安装就没什么复杂的了 1[root@localhost ~]# pip3 install selenium 三、安装PhantomJS使用命令确认下自己的系统版本，从官网 http://phantomjs.org/download.html 下载对应的安装包并解压 安装依赖包并建立软件界： 12[root@localhost ~]# yum -y install fontconfig[root@localhost ~]# ln -s /root/phantomjs/bin/phantomjs /usr/bin/ 验证是否安装成功： 1[root@localhost ~]# phantomjs --version 解压过程中可能会报错，运行的时候会提示Segmentation fault，这时候试着重命名下安装包再解压（网络众多教程均有重命名的操作，都没给出理由） 四、安装Scrapyd1.安装Python3和Scrapy安装成功后Scrapyd直接pip安装即可，所遇到的坑已在上文规避了。 1[root@localhost ~]# pip3 install scrapyd 验证是否安装成功： 1[root@localhost ~]# scrapyd --version 提示找不到命令则简历软链接； 1[root@localhost ~]# ln -s /usr/local/bin/scrapyd /usr/bin/scrapyd 2.配置文件新建一个 /etc/scrapyd/scrapyd.conf，Scrapy在运行的时候会读取此配置文件。 12[root@localhost ~]# sudo mkdir /etc/scrapyd[root@localhost ~]# sudo vi /etc/scrapyd/scrapyd.conf scrapyd启动的时候会自动搜索配置文件，配置文件的加载顺序如下，最后加载的设置会覆盖前面的设置： /etc/scrapyd/scrapyd.conf ~/etc/scrapyd/conf.d/* scrapyd.conf ~/.scrapyd.conf 官网配置文件：https://scrapyd.readthedocs.io/en/stable/config.html#config 1234567891011121314151617181920212223242526272829[scrapyd]eggs_dir = eggslogs_dir = logsitems_dir =jobs_to_keep = 5dbs_dir = dbsmax_proc = 0max_proc_per_cpu = 4finished_to_keep = 100poll_interval = 5.0bind_address = 0.0.0.0http_port = 6800debug = offrunner = scrapyd.runnerapplication = scrapyd.app.applicationlauncher = scrapyd.launcher.Launcherwebroot = scrapyd.website.Root[services]schedule.json = scrapyd.webservice.Schedulecancel.json = scrapyd.webservice.Canceladdversion.json = scrapyd.webservice.AddVersionlistprojects.json = scrapyd.webservice.ListProjectslistversions.json = scrapyd.webservice.ListVersionslistspiders.json = scrapyd.webservice.ListSpidersdelproject.json = scrapyd.webservice.DeleteProjectdelversion.json = scrapyd.webservice.DeleteVersionlistjobs.json = scrapyd.webservice.ListJobsdaemonstatus.json = scrapyd.webservice.DaemonStatus 安全起见可以配置bind_address 配置完成即可运行scrapyd访问 http://ip:port 看看效果 3.启动脚本编写创建目录：/var/scrapyd cd至/etc/rc.d/init.d/目录或者/etc/init.d/目录下，创建并编辑名为scrapyd的文件，其中的PORT、HOME、BIN根据实际情况修改： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/bin/bash# chkconfig: 2345 20 80# description: SrapydPORT=`cat /etc/scrapyd/scrapyd.conf |grep http_port | awk '&#123;print $3&#125;'`HOME="/var/scrapyd"BIN="/usr/local/bin/scrapyd" pid=`netstat -lnopt | grep :$PORT | awk '/python/&#123;gsub(/\/python3.7/,"",$7);print $7;&#125;'`start() &#123; if [ -n "$pid" ]; then echo "server already start,pid:$pid" return 0 fi cd $HOME nohup $BIN &gt;&gt; $HOME/scrapyd.log 2&gt;&amp;1 &amp; echo "start at port:$PORT"&#125; stop() &#123; if [ -z "$pid" ]; then echo "not find program on port:$PORT" return 0 fi kill -9 $pid echo "kill program use signal 9,pid:$pid"&#125; status() &#123; if [ -z "$pid" ]; then echo "not find program on port:$PORT" else echo "program is running,pid:$pid" fi&#125; case $1 in start) start ;; stop) stop ;; status) status ;; *) echo "Usage: &#123;start|stop|status&#125;" ;;esac exit 0 编辑完成后，为scrapyd文件增加执行权限： 1[root@localhost ~]# sudo chmod +x scrapyd 配置完就可以使用service scrapyd start等命令了。]]></content>
      <categories>
        <category>Python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
        <tag>scrapyd</tag>
        <tag>selenium</tag>
        <tag>phantomjs</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ngxin追加sticky模块实现session粘性]]></title>
    <url>%2Fposts%2F2019%2F05%2F08%2Fngxin%E8%BF%BD%E5%8A%A0sticky%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0session%E7%B2%98%E6%80%A7%2F</url>
    <content type="text"><![CDATA[由于公司的系统使用到session，刚做好的负载均衡多机环境下会导致取不到信息的问题，这里采用sticky模块解决。session粘性是一个比较省成本的解决方案，虽然有很多问题。 追加安装sticky模块1.下载地址：http://code.google.com/p/nginx-sticky-module/downloads/list 或者： wget https://code.google.com/p/nginx-sticky-module/downloads/detail?name=nginx-sticky-module-1.1.tar.gz 2.解压：1tar -xzvf nginx-sticky-module-1.1.tar.gz 3.进入nginx-1.9.3目录重新编译#运行：nginx -V 可以查看到之前的配置参数 重新配置nginx，添加第三方模块： 1[lmode@pnlvintf02 ~]$ ./configure --with-http_stub_status_module --with-http_ssl_module --add-module=../nginx-sticky-module-1.1 #(模块具体路径) 成功后运行 make 编译（添加模块的不要make install会吧原来的配置替换掉） 编译时错误解决： 12345cc1: warnings being treated as errorsngx_http_sticky_module.c: In function ‘ngx_http_get_sticky_peer’: /ngx_http_sticky_module.c:333: 警告：赋值时将整数赋给指针，未作类型转换ake[1]: *** [objs/addon/nginx-sticky-module-1.1/ngx_http_sticky_module.o] 错误 1 解决办法：把ngx_http_sticky_misc.c 的281行修改如下 原: 1digest-&gt;len = ngx_sock_ntop(in,digest-&gt;data, len, 1); 改后 1digest-&gt;len = ngx_sock_ntop(in,sizeof(struct sockaddr_in),digest-&gt;data, len, 1); 对nginx-sticky-module-1.1/ngx_http_sticky_module.c文件也进行修改（主要是nginx 1.9.x版本会出现这问题） 修改两个地方 第6行添加：1#include &lt;nginx.h&gt; 第333行左右修改（iphp-&gt;rrp.current = iphp-&gt;selected_peer;）为：12345#if defined(nginx_version) &amp;&amp; nginx_version &gt;= 1009000iphp-&gt;rrp.current = peer;#elseiphp-&gt;rrp.current = iphp-&gt;selected_peer;#endif 出现MD5相关报错：12ngx_http_sticky_misc.c: In function 「ngx_http_sticky_misc_md5」:ngx_http_sticky_misc.c:152:15: ERROR：「MD5_DIGEST_LENGTH」 undeclared (first use in this function) u_char hash[MD5_DIGEST_LENGTH]; 解决方式：修改在你下载解压缩之后的sticky模块文件夹中的ngx_http_sticky_misc.c文件 将这两个模块 &lt;openssl/sha.h&gt; and &lt;openssl/md5.h&gt;包含到文件ngx_http_sticky_misc.c 1234567891011#include &lt;nginx.h&gt;#include &lt;ngx_config.h&gt;#include &lt;ngx_core.h&gt;#include &lt;ngx_http.h&gt;#include &lt;ngx_md5.h&gt;#include &lt;ngx_sha1.h&gt;/*添加*/#include &lt;openssl/sha.h&gt;#include &lt;openssl/md5.h&gt;#include "ngx_http_sticky_misc.h" 4.在nginx-1.9.3目录，重新添加模块，编译12[lmode@pnlvintf02 ~]$ ./configure --with-http_stub_status_module --with-http_ssl_module --add-module=../nginx-sticky-module-1.1 #(模块具体路径)[lmode@pnlvintf02 ~]$ make (不要make install，要不然就相当于重新安装了。) 5.复制编译后的二进制文件到目录（拷贝前把服务停掉）123[lmode@pnlvintf02 ~]$ cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak[lmode@pnlvintf02 ~]$ cp /(nginx源码路径)/objs/nginx /usr/local/nginx/sbin/nginx 6.修改配置nginx文件,使插件sticky生效vi /usr/local/nginx/nginx.conf 在upstream中添加sticky; 123456789101112131415161718http &#123; upstream myproject&#123; #添加sticky模块后加入此配置 sticky; #被代理的服务 server 192.168.1.100:8081; server 192.168.1.101:8080; &#125; server &#123; #nginx监听的端口 listen 80; server_name localhost; location / &#123; #代理 proxy_pass http://myproject; &#125; &#125;&#125; 修改后sticky文件下载： 下载地址：nginx-sticky-module-1.1.zip]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>负载均衡</tag>
        <tag>session粘性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGINX负载均衡配置]]></title>
    <url>%2Fposts%2F2019%2F05%2F07%2FNGINX%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx负载均衡配置nginx能够配置代理多台服务器。当一台服务器宕机之后。仍能保持系统可用。 关键配置示例1234567891011121314151617181920212223http &#123; ... upstream nodes &#123; server 192.168.1.15:8080 weight=5; server 192.168.1.16:8080 weight=5; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; proxy_pass http://nodes; proxy_redirect default; #跟代理服务器连接的超时时间，必须留意这个time out时间不能超过75秒，当一台服务器当掉时，过10秒转发到另外一台服务器。 proxy_connect_timeout 10; &#125; ... &#125; ...&#125; upstream配置说明：轮询：1234upstream nodes &#123; server 192.168.10.1:8668; server 192.168.10.2:8668;&#125; 上面配置的上游服务器按照默认的轮询方式进行请求。如果上游服务器挂掉，能自己主动剔除，无需手动干预。这种方式简单快捷。但是如果上游服务器在配置不均衡的情况下，是解决不了的。 权重配置：weight和请求数量成正比，主要用于上游服务器配置不均衡的情况。下面的配置中，192.168.10.2机器的请求量是192.168.10.1机器请求量的2倍。1234upstream nodes &#123; server 192.168.10.1:8668 weight=5; server 192.168.10.2:8668 weight=10;&#125; fair 配置：公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法，必须下载Nginx的upstr_fair模块。 123456upstream backend &#123; server 192.168.1.101; server 192.168.1.102; server 192.168.1.103; fair;&#125; ip_hash配置：每一个请求按照请求的ip的hash结果分配。这样每一个请求固定落在一个上游服务器，能够解决ip会话在同一台服务器的问题。12345upstream nodes &#123; ip_hash; server 192.168.10.1:8668; server 192.168.10.2:8668;&#125; 注意：1、当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。2、导致负载不均衡。 upstream_hash配置：url_hash按照访问的url的hash结果来分配请求，使每一个url定向到同一个上游服务器。 注意：在upstream中加入hash语句。server语句中不能写入weight等其他的參数，hash_method是使用的hash算法。 123456upstream nodes &#123; server 192.168.10.1:8668; server 192.168.10.2:8668; hash $request_uri; hash_method crc32;&#125; upstream_hash这个第三方模块，这个模块多数情况下是用作url_hash的，但是并不妨碍将它用来做session共享： 上面的例子使用$request_uri做因子，稍微改一下： hash $http_x_forwarded_for; 这样就改成了利用x_forwarded_for这个头作因子，在nginx新版本中可支持读取cookie值，所以也可以改成： hash $cookie_jsessionid; upstream中常用的配置项：down：表示当前的server不參与负载均衡。 weight：默认1，weight越大，负载的权重就越大。 max_fails ：允许请求失败的次数，默认为1。即默认情况是只要发生错误就认为服务器挂掉了，如果将max_fails设置为0，则表示取消这项检查。 fail_timeout : max_fails次失败后，暂停请求此台服务器的时间。 backup： 其他全部的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。123456upstream nodes &#123; server 192.168.10.1:8668 down; server 192.168.10.2:8668 weight=2 max_fails=2 fail_timeout=1; ; server 192.168.10.3:8668 max_fails=2 fail_timeout=2; server 192.168.10.4:8668 backup;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crontab命令]]></title>
    <url>%2Fposts%2F2019%2F05%2F06%2Fcrontab%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一、crond简介crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。 Linux下的任务调度分为两类，系统任务调度和用户任务调度。 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。 /etc/crontab文件包括下面几行： [root@localhost ~]#cat /etc/crontab SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=””HOME=/ #run-parts 51 root run-parts /etc/cron.hourly 24 7 * root run-parts /etc/cron.daily 22 4 0 root run-parts /etc/cron.weekly 42 4 1 root run-parts /etc/cron.monthly [root@localhost ~]# 前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。 使用者权限文件： 文件： /etc/cron.deny 说明： 该文件中所列用户不允许使用crontab命令 文件： /etc/cron.allow 说明： 该文件中所列用户允许使用crontab命令 文件： /var/spool/cron/ 说明： 所有用户crontab文件存放的目录,以用户名命名 crontab文件的含义： 用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下： minute hour day month week command 其中： minute： 表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 二、crond服务安装crontab： yum install crontabs 服务操作说明： /sbin/service crond start //启动服务 /sbin/service crond stop //关闭服务 /sbin/service crond restart //重启服务 /sbin/service crond reload //重新载入配置 查看crontab服务状态： service crond status 手动启动crontab服务： service crond start 查看crontab服务是否已设置为开机启动，执行命令： ntsysv 加入开机自动启动： chkconfig –level 35 crond on 三、crontab命令详解1．命令格式：crontab [-u user] file crontab [-u user] [ -e | -l | -r ] 2．命令功能：通过crontab 命令，我们可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常设合周期性的日志分析或数据备份等工作。 3．命令参数：-u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 4．常用方法：1). 创建一个新的crontab文件在考虑向cron进程提交一个crontab文件之前，首先要做的一件事情就是设置环境变量EDITOR。cron进程根据它来确定使用哪个编辑器编辑crontab文件。9 9 %的UNIX和LINUX用户都使用vi，如果你也是这样，那么你就编辑$ HOME目录下的. profile文件，在其中加入这样一行： EDITOR=vi; export EDITOR 然后保存并退出。不妨创建一个名为 cron的文件，其中 是用户名，例如， davecron。在该文件中加入如下的内容。 # (put your own initials here)echo the date to the console every # 15minutes between 6pm and 6am 0,15,30,45 18-06 * /bin/echo ‘date’ &gt; /dev/console ​ 保存并退出。确信前面5个域用空格分隔。 在上面的例子中，系统将每隔1 5分钟向控制台输出一次当前时间。如果系统崩溃或挂起，从最后所显示的时间就可以一眼看出系统是什么时间停止工作的。在有些系统中，用tty1来表示控制台，可以根据实际情况对上面的例子进行相应的修改。为了提交你刚刚创建的crontab文件，可以把这个新创建的文件作为cron命令的参数： $ crontab davecron 现在该文件已经提交给cron进程，它将每隔1 5分钟运行一次。 同时，新创建文件的一个副本已经被放在/var/spool/cron目录中，文件名就是用户名(即dave)。 2). 列出crontab文件 为了列出crontab文件，可以用： $ crontab -l 0,15,30,45,18-06 * /bin/echo date &gt; dev/tty1 你将会看到和上面类似的内容。可以使用这种方法在$ H O M E目录中对crontab文件做一备份： $ crontab -l &gt; $HOME/mycron ​ 这样，一旦不小心误删了crontab文件，可以用上一节所讲述的方法迅速恢复。 3). 编辑crontab文件 如果希望添加、删除或编辑crontab文件中的条目，而E D I TO R环境变量又设置为v i，那么就可以用v i来编辑crontab文件，相应的命令为： $ crontab -e 可以像使用v i编辑其他任何文件那样修改crontab文件并退出。如果修改了某些条目或添加了新的条目，那么在保存该文件时， c r o n会对其进行必要的完整性检查。如果其中的某个域出现了超出允许范围的值，它会提示你。 我们在编辑crontab文件时，没准会加入新的条目。例如，加入下面的一条： # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month 30 3 1,7,14,21,26 /bin/find -name “core’ -exec rm {} \; 现在保存并退出。最好在crontab文件的每一个条目之上加入一条注释，这样就可以知道它的功能、运行时间，更为重要的是，知道这是哪位用户的作业。 现在让我们使用前面讲过的crontab -l命令列出它的全部信息： $ crontab -l # (crondave installed on Tue May 4 13:07:43 1999) # DT:ech the date to the console every 30 minites 0,15,30,45 18-06 * /bin/echo date &gt; /dev/tty1 # DT:delete core files,at 3.30am on 1,7,14,21,26,26 days of each month 30 3 1,7,14,21,26 /bin/find -name “core’ -exec rm {} \; 4). 删除crontab文件要删除crontab文件，可以用： $ crontab -r 5). 恢复丢失的crontab文件如果不小心误删了crontab文件，假设你在自己的$ H O M E目录下还有一个备份，那么可以将其拷贝到/var/spool/cron/ ，其中 是用户名。如果由于权限问题无法完成拷贝，可以用： $ crontab ​ 其中， 是你在$ H O M E目录中副本的文件名。 我建议你在自己的$ H O M E目录中保存一个该文件的副本。我就有过类似的经历，有数次误删了crontab文件（因为r键紧挨在e键的右边）。这就是为什么有些系统文档建议不要直接编辑crontab文件，而是编辑该文件的一个副本，然后重新提交新的文件。 有些crontab的变体有些怪异，所以在使用crontab命令时要格外小心。如果遗漏了任何选项，crontab可能会打开一个空文件，或者看起来像是个空文件。这时敲delete键退出，不要按 ，否则你将丢失crontab文件。 6)．使用实例实例1：每1分钟执行一次command 命令： * command 实例2：每小时的第3和第15分钟执行 命令： 3,15 command 实例3：在上午8点到11点的第3和第15分钟执行 命令： 3,15 8-11 * command 实例4：每隔两天的上午8点到11点的第3和第15分钟执行 命令： 3,15 8-11 /2 * command 实例5：每个星期一的上午8点到11点的第3和第15分钟执行 命令： 3,15 8-11 1 command 实例6：每晚的21:30重启smb 命令： 30 21 * /etc/init.d/smb restart 实例7：每月1、10、22日的4 : 45重启smb 命令： 45 4 1,10,22 /etc/init.d/smb restart 实例8：每周六、周日的1 : 10重启smb 命令： 10 1 6,0 /etc/init.d/smb restart 实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb 命令： 0,30 18-23 * /etc/init.d/smb restart 实例10：每星期六的晚上11 : 00 pm重启smb 命令： 0 23 6 /etc/init.d/smb restart 实例11：每一小时重启smb 命令： * /1 /etc/init.d/smb restart 实例12：晚上11点到早上7点之间，每隔一小时重启smb 命令： * 23-7/1 * /etc/init.d/smb restart 实例13：每月的4号与每周一到周三的11点重启smb 命令： 0 11 4 * mon-wed /etc/init.d/smb restart 实例14：一月一号的4点重启smb 命令： 0 4 1 jan * /etc/init.d/smb restart 实例15：每小时执行/etc/cron.hourly目录内的脚本 命令： 01 root run-parts /etc/cron.hourly 说明： run-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了 四、使用注意事项1. 注意环境变量问题有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。 在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。 不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点： 1）脚本中涉及文件路径时写全局路径； 2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如： cat start_cbp.sh #!/bin/sh source /etc/profile export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf /usr/local/jboss-4.0.5/bin/run.sh -c mev &amp; 3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如： 0 . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh 2. 注意清理系统用户的邮件日志每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。 例如，可以在crontab文件中设置如下形式，忽略日志输出： 0 /3 /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1 “/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。 3. 系统级任务调度与用户级任务调度系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。 4.其他注意事项新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\%Y\%m\%d’ 。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fposts%2F2019%2F04%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
